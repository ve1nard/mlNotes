{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias-Variance Decomposition of Mean Squared Error\n",
    "* $x$ be a fixed input\n",
    "* $y = f(x) + \\varepsilon$ where $\\varepsilon$ is noise with $\\mathbb{E}[\\varepsilon] = 0$ and $\\operatorname{Var}(\\varepsilon) = \\sigma^2$\n",
    "* $\\hat{f}_D(x)$ be the prediction of a model trained on dataset $D$\n",
    "\n",
    "\n",
    "We analyze the expected squared error:\n",
    "$$\n",
    "\\mathbb{E}_{D,\\varepsilon}[(y - \\hat{f}_D(x))^2]\n",
    "$$\n",
    "\n",
    "Substitute $y = f(x) + \\varepsilon$:\n",
    "$$\n",
    "= \\mathbb{E}_{D,\\varepsilon}[(f(x) + \\varepsilon - \\hat{f}_D(x))^2]\n",
    "$$\n",
    "\n",
    "Group terms:\n",
    "$$\n",
    "= \\mathbb{E}_{D,\\varepsilon}[(f(x) - \\hat{f}_D(x) + \\varepsilon)^2]\n",
    "$$\n",
    "\n",
    "Expand the square:\n",
    "$$\n",
    "= \\mathbb{E}_{D,\\varepsilon}[(f(x) - \\hat{f}_D(x))^2 + 2(f(x) - \\hat{f}_D(x))\\varepsilon + \\varepsilon^2]\n",
    "$$\n",
    "\n",
    "Use linearity of expectation:\n",
    "$$\n",
    "= \\mathbb{E}_D[(f(x) - \\hat{f}_D(x))^2] + 2\\mathbb{E}_{D,\\varepsilon}[(f(x) - \\hat{f}_D(x))\\varepsilon] + \\mathbb{E}_\\varepsilon[\\varepsilon^2]\n",
    "$$\n",
    "\n",
    "### Vanishing Cross-Term\n",
    "\n",
    "The cross-term:\n",
    "$$\n",
    "\\mathbb{E}_{D,\\varepsilon}[(f(x) - \\hat{f}_D(x))\\varepsilon]\n",
    "$$\n",
    "\n",
    "Since $\\hat{f}_D(x)$ depends only on $D$ and $\\varepsilon$ is independent of $D$, and $\\mathbb{E}[\\varepsilon] = 0$:\n",
    "$$\n",
    "= \\mathbb{E}_D\\left[(f(x) - \\hat{f}_D(x)) \\cdot \\mathbb{E}_\\varepsilon[\\varepsilon]\\right] = 0\n",
    "$$\n",
    "\n",
    "So:\n",
    "$$\n",
    "\\mathbb{E}_{D,\\varepsilon}[(y - \\hat{f}_D(x))^2] = \\mathbb{E}_D[(f(x) - \\hat{f}_D(x))^2] + \\sigma^2\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Now apply the following identity to the first term:\n",
    "\n",
    "\\subsection*{Theorem: Decomposition of Expected Squared Distance from Constant}\n",
    "\n",
    "Let $Z$ be a random variable and $a \\in \\mathbb{R}$ a constant. Then:\n",
    "$$\n",
    "\\mathbb{E}[(a - Z)^2] = (a - \\mathbb{E}[Z])^2 + \\mathbb{E}[(Z - \\mathbb{E}[Z])^2]\n",
    "$$\n",
    "\n",
    "\\textbf{Proof:}\n",
    "\n",
    "Let $\\mu = \\mathbb{E}[Z]$, then:\n",
    "\\begin{align*}\n",
    "\\mathbb{E}[(a - Z)^2] &= \\mathbb{E}[(a - \\mu + \\mu - Z)^2] \\\\\n",
    "&= \\mathbb{E}[(a - \\mu)^2 + 2(a - \\mu)(\\mu - Z) + (\\mu - Z)^2] \\\\\n",
    "&= (a - \\mu)^2 + 2(a - \\mu)\\mathbb{E}[\\mu - Z] + \\mathbb{E}[(\\mu - Z)^2] \\\\\n",
    "&= (a - \\mu)^2 + 0 + \\mathbb{E}[(Z - \\mu)^2] \\\\\n",
    "&= (a - \\mathbb{E}[Z])^2 + \\operatorname{Var}(Z)\n",
    "\\end{align*}\n",
    "\n",
    "$\\blacksquare$\n",
    "\n",
    "---\n",
    "\n",
    "Apply this identity with $a = f(x)$ and $Z = \\hat{f}_D(x)$:\n",
    "$$\n",
    "\\mathbb{E}_D[(f(x) - \\hat{f}_D(x))^2] = (f(x) - \\mathbb{E}_D[\\hat{f}_D(x)])^2 + \\mathbb{E}_D[(\\hat{f}_D(x) - \\mathbb{E}_D[\\hat{f}_D(x)])^2]\n",
    "$$\n",
    "\n",
    "So the total error becomes:\n",
    "$$\n",
    "\\mathbb{E}_{D,\\varepsilon}[(y - \\hat{f}_D(x))^2] = \\underbrace{(f(x) - \\mathbb{E}_D[\\hat{f}_D(x)])^2}_{\\text{Bias}^2} + \\underbrace{\\mathbb{E}_D[(\\hat{f}_D(x) - \\mathbb{E}_D[\\hat{f}_D(x)])^2]}_{\\text{Variance}} + \\underbrace{\\sigma^2}_{\\text{Irreducible noise}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "\\section*{Global (Integrated) Bias-Variance Decomposition}\n",
    "\n",
    "If $x$ is not fixed but comes from a distribution $p(x)$, the overall expected error is:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_x\\left[\\mathbb{E}_{D,\\varepsilon}[(y - \\hat{f}_D(x))^2]\\right]\n",
    "= \\mathbb{E}_x[(\\text{Bias}(x))^2 + \\text{Var}(x) + \\sigma^2]\n",
    "$$\n",
    "\n",
    "This integral is typically approximated in practice by averaging over a large test set of inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
